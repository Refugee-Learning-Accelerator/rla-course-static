# Challenge 3 Final Project

*AR Experience: https://drive.google.com/open?id=1ZvOr21uQ1yPCELLViwULPMqgWlCGX_6D*

*VR Experience: https://drive.google.com/open?id=1h5San3Hnv25p0nKnijUPvNS3xWz8EFMH*

## Description

*A famous Arab saying states that "لا حياء في علم" or “there is no modesty in science”. This saying was our driver for this challenge. Our project is divided into two experiences: AR and VR. The first experience is allowing the user to use the phone camera to detect images which contain scenarios, exams or organs that could be discussed with an OBGYN.  Words in Arabic and English are augmented on these images in order to teach them to female users over 21 years old. After learning the terms in AR, the user is placed in a VR scenario at the OBGYN’s office. The virtual doctor asks yes no questions using the words learned in the AR experience. The AR experience is to teach women how to speak to doctors in English without a translator, which maintains their privacy. The VR is to help women to overcome barriers, whether they were cultural barriers or just simple shyness. PLEASE CHECK ATTACHED VIDEOS FOR DEMO*

## Questions

### How did you build it? (Platform and technology)

*Both experiences were built using Unity3D. AR needed Vuforia tools. The final product was built on Android.**

### What challenges did you face?

*Speech recognition was the main challenge we faced. As Hisham mentioned in the seminar, it is not elegantly developed for Unity. We could not allow speech recognition to press a UI button, and we are not sure if it is even possible. Also programming a VR cursor with Raycasts and clicking functions was a bit difficult, it was impossible to test since we do not have a VR set. Therefore, we used the mouse to click, and added a code to move the camera around to show what the VR feels like when the user moves her head around. Switching “Main Cameras” for the VR experience was a bit challenging in the beginning, so we settled for Scene management beginning which turned out to be a bit better to design*

### What aspect of the AR experience do you like best? 

*Having infinite possibilities for AR was the best aspect for us. For this proof of concept, we only augmented 3D text on the images, but we also could have augmented 3D images of body parts just like many medical/biology experience available in the oculus store, play store and others we found in literature. Having an Arabic Support was a true life saver, otherwise we could have had a huge gap in our teaching approach.*

### What would you different in the future? 

*For starters, we would have consulted a proper graphic designer to provide great rendering for the clinic and doctors instead of settling for the free game objects we found online. The fact that we added a user defined array size means that we can add as many questions as possible, but in the future, we probably need more than just Yes/No questions. Despite the fact that we contacted an NGO and a couple of doctors, we could ask doctors to test it out, and even get approvals to let their patients use it. Crossing/Teasing with the ethical line would be adding equipment that could simulate where the doctor is placing his hands/equipment, but this is far beyond our current capabilities, and it also needs a lot of approvals and discussions with ethical committees.*

### Please also add a link to your code!

*https://drive.google.com/open?id=1jGrTAUHpscFBFyZKJSLvXMQlYX9HbktZ*
