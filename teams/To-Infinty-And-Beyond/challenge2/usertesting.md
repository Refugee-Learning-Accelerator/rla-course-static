# Challenge 2 User Testing

Problem Statement:
How might we design a translation tool that makes refugee students feel empowered?

Description:
Our prototype is an OCR-based translation tool that has been designed to be simple, handy, practical, and efficient. It can be implemented as an app on hand-held devices (e.g. smartphones, tablets) and uses its camera to capture the content to be translated. Then it performs OCR (Optical Character Recognition) to recognize and locate the characters within the images and output them as a text script. The latter is then parsed and sent to a state-of-art translator to output it in Arabic.
To demonstrate the concept, we have created an executable version of it that uploads the captured image and applies state-of-art OCR stage by google and English-to-Arabic translator by Yandex to output the final results. 
Here is a video of it illustrating the idea: https://www.youtube.com/watch?v=zM8OdJ70Cbw 


### How did you select your test users? 

Ideally, the end users for our prototype are the Syrian refugee students located in the hosting countries of English-based educational curriculum. However due to the time constrain for this challenge, we had decided to publish the conceptual prototype through the Syrian Society for Scientific Research network which includes currently ~ 100 members of Syrian researchers all over the world. We were also interested in collecting feedback from those who are working in the translation field, hence, we had reached some translation groups and published our questionnaire on their social pages. Unfortunately, only eight members in these groups have corresponded to the questionnaire, which limits the evaluation results of our application.

### What was the setting of the test? 

We had created an internal event on facebook to better reach out to more members in the targeted groups. To better analyze and generate statistics, we have added many multi-choice questions while keeping few for open-ended discussions and suggestions. Please refer to the questionnaire sheet to fully observe the test set: https://goo.gl/JgLLXy.

### What were the main points of feedback you received (share a summary)? 

On a scale of 1 to 5, with 1 referring to ‘worst’ and 5 to ‘excellent’ performance, we asked the participant for a feedback about the performance of the translation app using an online Google form. We performed preliminary assessments on the usability (defined as ease of use), accuracy of the OCR function and English-Arabic translation (defined as the correctness of comprehensiveness of the translated materials) and clarity of the Arabic sentence. The evaluation was performed qualitatively with respect to all evaluated issues, i.e., no similarity index between the translated and reference texts was used. We asked the participant for additional explanations of the main drawbacks and ideas of future applications, as well.
Figure 1 (on folder) summarizes the evaluations collected from the questionnaire. The feedback has provided a positive impact about the quality of the tool. The usability has obtained 4 degrees by 3 (37.5%) participants, whereas the accuracy has obtained 3 degrees by 3 (37.5%) participants, which indicates a moderate performance. The user interface was negatively evaluated with 2 degrees by 3 participants, which necessitates a focus on this part of the app for making it more attractive and user-friendly. The translation accuracy, in terms of word-to-word translation using Yandex was moderately to positively evaluated (4 degrees by 50% of participants for both the moderate and good scores). This might emphasize the feasibility of Yandex for English-Arabic translation. However, the clarity of the Arabic text has obtained various evaluations, including 1 degree by one participant. This result implies the necessity of the Deep Learning-based translation tool to be developed in our project.
The participants have provided us with additional comments. Considering the Human Centered Design approach, the most important comment was providing the app with features that enable the user to adapt the translated text by either selecting appropriate translations or editing the translation manually. In addition, negative comments have been submitted about the word-by-word translation approach, which dramatically affected the context of the output sentences. Collectively, these opinions will be assistive for the coming developments.

### What changes would make to your idea/project based on the feedback?

The main changes in the idea will focus on improving the usability of the app at the interface level, and extending the translation functionality to be more adaptable by the user. When we designed the tool, we thought about the total automation of the translation process as an ideal concept. However, due to current limitations in the quality of online translation services in context-based translation, the user interaction would be an important function to be added to the tool in the current level of development. In the same time, we need to empathize in the following development stages, so that we do not impose a large burden on the user in modifying the translated text, especially knowing that they might lack the essential lingual needs to the education dropout. Anyway, the higher automation levels might be approachable by focusing further on the context-based translation functionality using Deep Learning-based NLP utilities.

### What parts of the Human Centered Design process were new to you?

The empathize stage, as developers we used to directly jump to the solutions and the coding parts before even understanding the real-problem.

### What parts of the Human Centered Design process seemed most useful to you?

The synthesize and ideate phases as they helped us better state the problem based on the real-need and brainstorm to come up with good solutions.
